import os
import torch
import torch.nn as nn
from torchvision import transforms, models
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from PIL import Image
import pandas as pd
from tqdm import tqdm
import json

# ===== 1. è®¾ç½®è·¯å¾„ =====
vit_dir = "/data_hdd/lzh/hair_second/ViT_EfficientNet/20250812/vit_hyper"
test_dir = "/data_hdd/lzh/hair_second/dataset_20250527/2025_15_100"
output_csv = "vit_evaluation_results.csv"

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# ===== 2. å›¾åƒé¢„å¤„ç† =====
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

def gray_loader(path):
    return Image.open(path).convert("RGB")

# ===== 3. åŠ è½½æµ‹è¯•é›† =====
test_dataset = ImageFolder(root=test_dir, transform=transform, loader=gray_loader)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8)
num_classes = len(test_dataset.classes)

# ===== 4. æ¨¡å‹åŠ è½½å‡½æ•° =====
def load_model(pth_path, class_to_idx_path):
    # Load class_to_idx mapping
    with open(class_to_idx_path, 'r') as f:
        class_to_idx = json.load(f)
    
    # Initialize ViT model
    model = models.vit_b_16(weights=None)
    model.heads.head = nn.Linear(model.heads.head.in_features, len(class_to_idx))
    
    # Load trained weights
    model.load_state_dict(torch.load(pth_path, map_location=device))
    return model.to(device)

# ===== 5. æµ‹è¯•å‡½æ•° =====
def evaluate_model(model):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc="Evaluating"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return correct / total

# ===== 6. éå†æ‰€æœ‰æ¨¡å‹å¹¶è¯„ä¼° =====
results = []

for file in os.listdir(vit_dir):
    if file.endswith(".pth"):
        # Find corresponding class_to_idx file
        per_tag = file.split("_")[-1].replace(".pth", "")
        class_to_idx_file = f"class_to_idx_{per_tag}.json"
        class_to_idx_path = os.path.join(vit_dir, class_to_idx_file)
        
        if not os.path.exists(class_to_idx_path):
            print(f"[è·³è¿‡] {file} ç¼ºå°‘å¯¹åº”çš„class_to_idxæ–‡ä»¶")
            continue
            
        pth_path = os.path.join(vit_dir, file)
        print(f"\nğŸ” æ­£åœ¨æµ‹è¯•æ¨¡å‹: {file}")
        try:
            model = load_model(pth_path, class_to_idx_path)
            acc = evaluate_model(model)
            results.append({
                "model_type": "vit",
                "file_name": file,
                "top1_acc": round(acc, 4),
                "dataset": per_tag
            })
        except Exception as e:
            print(f"[è·³è¿‡] {file} åŠ è½½å¤±è´¥: {e}")

# ===== 7. ä¿å­˜ç»“æœ =====
df = pd.DataFrame(results)
df.to_csv(output_csv, index=False)
print(f"\nâœ… æ‰€æœ‰ViTæ¨¡å‹æµ‹è¯•å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š{output_csv}")